{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0cf22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f79cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab546ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1613s\u001b[0m 10us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Define the number of bins for the histogram\n",
    "num_bins = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15745407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HOG parameters\n",
    "cell_size = (4, 4)           # Size of each cell in pixels\n",
    "block_size = (2, 2)          # Number of cells in a block\n",
    "block_stride = (4, 4)        # Step size for block movement\n",
    "win_size = (32, 32)          # Same as image size\n",
    "nbins = 9                    # Number of orientation bins\n",
    "\n",
    "# Initialize HOG descriptor\n",
    "hog = cv2.HOGDescriptor(\n",
    "    _winSize=(win_size[1], win_size[0]),\n",
    "    _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),\n",
    "    _blockStride=(block_stride[1], block_stride[0]),\n",
    "    _cellSize=(cell_size[1], cell_size[0]),\n",
    "    _nbins=nbins\n",
    ")\n",
    "\n",
    "# Function to compute HOG features for the dataset\n",
    "def compute_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        hog_feats = hog.compute(img).flatten()  # Flatten to 1D vector\n",
    "        features.append(hog_feats)\n",
    "    return np.array(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0a843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HOG feature shape: (50000, 1764)\n",
      "Test HOG feature shape: (10000, 1764)\n"
     ]
    }
   ],
   "source": [
    "# Convert images to grayscale\n",
    "x_train_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in x_train])\n",
    "x_test_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in x_test])\n",
    "\n",
    "# Extract HOG features for training and test datasets\n",
    "x_train_hog = compute_hog_features(x_train_gray)\n",
    "x_test_hog = compute_hog_features(x_test_gray)\n",
    "\n",
    "print(f\"Training HOG feature shape: {x_train_hog.shape}\")\n",
    "print(f\"Test HOG feature shape: {x_test_hog.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f5d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract color histogram features\n",
    "def color_histogram(image):\n",
    "    # Convert image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Calculate histograms for each color channel\n",
    "    hist_h = cv2.calcHist([hsv_image], [0], None, [num_bins], [0, 180])  # Hue\n",
    "    hist_s = cv2.calcHist([hsv_image], [1], None, [num_bins], [0, 256])  # Saturation\n",
    "    hist_v = cv2.calcHist([hsv_image], [2], None, [num_bins], [0, 256])  # Value\n",
    "\n",
    "    # Normalize histograms\n",
    "    cv2.normalize(hist_h, hist_h, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    cv2.normalize(hist_s, hist_s, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    cv2.normalize(hist_v, hist_v, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "    # Concatenate histograms into a single feature vector\n",
    "    histogram = np.concatenate((hist_h, hist_s, hist_v), axis=0)\n",
    "\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fcfd244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (50000, 768, 1)\n",
      "Test features shape: (10000, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "# Extract features from training and test data\n",
    "train_features_color = []\n",
    "for image in x_train:\n",
    "    feature_c = color_histogram(image)\n",
    "    train_features_color.append(feature_c)\n",
    "\n",
    "test_features_color = []\n",
    "for image in x_test:\n",
    "    feature_c_test = color_histogram(image)\n",
    "    test_features_color.append(feature_c_test)\n",
    "\n",
    "# Convert feature lists to NumPy arrays\n",
    "train_features_color = np.array(train_features_color)\n",
    "test_features_color = np.array(test_features_color)\n",
    "\n",
    "print(\"Training features shape:\", train_features_color.shape)\n",
    "print(\"Test features shape:\", test_features_color.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db362fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute LBP histogram\n",
    "def lbp_histogram(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply LBP operator\n",
    "    lbp = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    lbp = cv2.normalize(lbp, lbp, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Flatten the histogram\n",
    "    hist = lbp.flatten()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bb7b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (50000, 256)\n",
      "Test features shape: (10000, 256)\n"
     ]
    }
   ],
   "source": [
    "# Extract features from training\n",
    "train_features_lbp = []\n",
    "for image in x_train:\n",
    "    feature_lbp = lbp_histogram(image)\n",
    "    train_features_lbp.append(feature_lbp)\n",
    "    \n",
    "# Extract features from test data\n",
    "test_features_lbp = []\n",
    "for image in x_test:\n",
    "    feature_lbp = lbp_histogram(image)\n",
    "    test_features_lbp.append(feature_lbp)\n",
    "    \n",
    "# Convert feature lists to NumPy arrays\n",
    "train_features_lbp = np.array(train_features_lbp)\n",
    "test_features_lbp = np.array(test_features_lbp)\n",
    "\n",
    "print(\"Training features shape:\", train_features_lbp.shape)\n",
    "print(\"Test features shape:\", test_features_lbp.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
