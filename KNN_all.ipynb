{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8634066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a338f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 17:27:25.766464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcaa9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Define the number of bins for the histogram\n",
    "num_bins = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c44f7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HOG parameters\n",
    "cell_size = (4, 4)           # Size of each cell in pixels\n",
    "block_size = (2, 2)          # Number of cells in a block\n",
    "block_stride = (4, 4)        # Step size for block movement\n",
    "win_size = (32, 32)          # Same as image size\n",
    "nbins = 9                    # Number of orientation bins\n",
    "\n",
    "# Initialize HOG descriptor\n",
    "hog = cv2.HOGDescriptor(\n",
    "    _winSize=(win_size[1], win_size[0]),\n",
    "    _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),\n",
    "    _blockStride=(block_stride[1], block_stride[0]),\n",
    "    _cellSize=(cell_size[1], cell_size[0]),\n",
    "    _nbins=nbins\n",
    ")\n",
    "\n",
    "# Function to compute HOG features for the dataset\n",
    "def compute_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        hog_feats = hog.compute(img).flatten()  # Flatten to 1D vector\n",
    "        features.append(hog_feats)\n",
    "    return np.array(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3484027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HOG feature shape: (50000, 1764)\n",
      "Test HOG feature shape: (10000, 1764)\n"
     ]
    }
   ],
   "source": [
    "# Convert images to grayscale\n",
    "x_train_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in x_train])\n",
    "x_test_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in x_test])\n",
    "\n",
    "# Extract HOG features for training and test datasets\n",
    "x_train_hog = compute_hog_features(x_train_gray)\n",
    "x_test_hog = compute_hog_features(x_test_gray)\n",
    "\n",
    "print(f\"Training HOG feature shape: {x_train_hog.shape}\")\n",
    "print(f\"Test HOG feature shape: {x_test_hog.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "721ed793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e134e7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HOG feature shape: (50000, 1)\n",
      "Test HOG feature shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca1 = PCA(n_components=1)\n",
    "pca2 = PCA(n_components=1)\n",
    "# Fit the PCA model to the data\n",
    "pca1.fit(x_train_hog)\n",
    "\n",
    "# Transform the data to the new lower-dimensional space\n",
    "x_train_hog = pca1.transform(x_train_hog)\n",
    "\n",
    "pca2.fit(x_test_hog)\n",
    "\n",
    "# Transform the data to the new lower-dimensional space\n",
    "x_test_hog = pca2.transform(x_test_hog)\n",
    "\n",
    "print(f\"Training HOG feature shape: {x_train_hog.shape}\")\n",
    "print(f\"Test HOG feature shape: {x_test_hog.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6c7dac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract color histogram features\n",
    "def color_histogram(image):\n",
    "    # Convert image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Calculate histograms for each color channel\n",
    "    hist_h = cv2.calcHist([hsv_image], [0], None, [num_bins], [0, 180])  # Hue\n",
    "    hist_s = cv2.calcHist([hsv_image], [1], None, [num_bins], [0, 256])  # Saturation\n",
    "    hist_v = cv2.calcHist([hsv_image], [2], None, [num_bins], [0, 256])  # Value\n",
    "\n",
    "    # Normalize histograms\n",
    "    cv2.normalize(hist_h, hist_h, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    cv2.normalize(hist_s, hist_s, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    cv2.normalize(hist_v, hist_v, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "    # Concatenate histograms into a single feature vector\n",
    "    histogram = np.concatenate((hist_h, hist_s, hist_v), axis=0)\n",
    "\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6a971410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (50000, 768, 1)\n",
      "Test features shape: (10000, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "# Extract features from training and test data\n",
    "train_features_color = []\n",
    "for image in x_train:\n",
    "    feature_c = color_histogram(image)\n",
    "    train_features_color.append(feature_c)\n",
    "\n",
    "test_features_color = []\n",
    "for image in x_test:\n",
    "    feature_c_test = color_histogram(image)\n",
    "    test_features_color.append(feature_c_test)\n",
    "\n",
    "# Convert feature lists to NumPy arrays\n",
    "train_features_color = np.array(train_features_color)\n",
    "test_features_color = np.array(test_features_color)\n",
    "\n",
    "print(\"Training features shape:\", train_features_color.shape)\n",
    "print(\"Test features shape:\", test_features_color.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "84cda9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute LBP histogram\n",
    "def lbp_histogram(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply LBP operator\n",
    "    lbp = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    lbp = cv2.normalize(lbp, lbp, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Flatten the histogram\n",
    "    hist = lbp.flatten()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f92d241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (50000, 256)\n",
      "Test features shape: (10000, 256)\n"
     ]
    }
   ],
   "source": [
    "# Extract features from training\n",
    "train_features_lbp = []\n",
    "for image in x_train:\n",
    "    feature_lbp = lbp_histogram(image)\n",
    "    train_features_lbp.append(feature_lbp)\n",
    "    \n",
    "# Extract features from test data\n",
    "test_features_lbp = []\n",
    "for image in x_test:\n",
    "    feature_lbp = lbp_histogram(image)\n",
    "    test_features_lbp.append(feature_lbp)\n",
    "    \n",
    "# Convert feature lists to NumPy arrays\n",
    "train_features_lbp = np.array(train_features_lbp)\n",
    "test_features_lbp = np.array(test_features_lbp)\n",
    "\n",
    "print(\"Training features shape:\", train_features_lbp.shape)\n",
    "print(\"Test features shape:\", test_features_lbp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b0352497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HOG feature shape: (50000, 1)\n",
      "Test HOG feature shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "pca3 = PCA(n_components=1)\n",
    "pca4 = PCA(n_components=1)\n",
    "# Fit the PCA model to the data\n",
    "pca3.fit(train_features_lbp)\n",
    "\n",
    "# Transform the data to the new lower-dimensional space\n",
    "train_features_lbp = pca3.transform(train_features_lbp)\n",
    "\n",
    "pca4.fit(test_features_lbp)\n",
    "\n",
    "# Transform the data to the new lower-dimensional space\n",
    "test_features_lbp = pca4.transform(test_features_lbp)\n",
    "\n",
    "print(f\"Training HOG feature shape: {train_features_lbp.shape}\")\n",
    "print(f\"Test HOG feature shape: {test_features_lbp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05b9cfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, *, edgecolors=None, plotnonfinite=False, data=None, **kwargs)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Select a random image from the training set\n",
    "#index = np.random.randint(len(x_train))\n",
    "#img = x_train[index]\n",
    "\n",
    "#feature_lbp=feature_lbp.reshape(32, 32)\n",
    "#feature_lbp = lbp_histogram(img)\n",
    "\n",
    "#plt.imshow(img)\n",
    "#plt.imshow(feature_lbp)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0fa0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "class KNN():\n",
    "  def __init__(self,k):\n",
    "    self.k=k\n",
    "    \n",
    "  def fit(self,X_train,y_train):\n",
    "    self.x_train=X_train\n",
    "    self.y_train=y_train\n",
    "    \n",
    "  def calculate_euclidean(self,sample1,sample2):\n",
    "    distance=0.0\n",
    "    for i in range(len(sample1)):\n",
    "      distance+=(sample1[i]-sample2[i])**2 #Euclidean Distance = sqrt(sum i to N (x1_i – x2_i)^2)\n",
    "    return sqrt(distance)\n",
    "\n",
    "  def nearest_neighbors(self,test_sample):\n",
    "    distances=[]#calculate distances from a test sample to every sample in a training set\n",
    "    for i in range(len(self.x_train)):\n",
    "      distances.append((self.y_train[i],self.calculate_euclidean(self.x_train[i],test_sample)))\n",
    "    distances.sort(key=lambda x:x[1])#sort in ascending order, based on a distance value\n",
    "    neighbors=[]\n",
    "    for i in range(self.k): #get first k samples\n",
    "      neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    "\n",
    "  def predict(self,test_set):\n",
    "    predictions=[]\n",
    "    for test_sample in test_set:\n",
    "      neighbors=self.nearest_neighbors(test_sample)\n",
    "      labels=[sample for sample in neighbors]\n",
    "      prediction=max(labels,key=labels.count)\n",
    "      predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b1bf0fe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m clf\u001b[38;5;241m=\u001b[39mKNN(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(x_train_hog,y_train)\n\u001b[0;32m----> 3\u001b[0m predictions\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mpredict(x_test_hog)\n",
      "Cell \u001b[0;32mIn[141], line 29\u001b[0m, in \u001b[0;36mKNN.predict\u001b[0;34m(self, test_set)\u001b[0m\n\u001b[1;32m     27\u001b[0m predictions\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_sample \u001b[38;5;129;01min\u001b[39;00m test_set:\n\u001b[0;32m---> 29\u001b[0m   neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnearest_neighbors(test_sample)\n\u001b[1;32m     30\u001b[0m   labels\u001b[38;5;241m=\u001b[39m[sample \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m neighbors]\n\u001b[1;32m     31\u001b[0m   prediction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(labels,key\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mcount)\n",
      "Cell \u001b[0;32mIn[141], line 19\u001b[0m, in \u001b[0;36mKNN.nearest_neighbors\u001b[0;34m(self, test_sample)\u001b[0m\n\u001b[1;32m     17\u001b[0m distances\u001b[38;5;241m=\u001b[39m[]\u001b[38;5;66;03m#calculate distances from a test sample to every sample in a training set\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train)):\n\u001b[0;32m---> 19\u001b[0m   distances\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[i],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_euclidean(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train[i],test_sample)))\n\u001b[1;32m     20\u001b[0m distances\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x:x[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;66;03m#sort in ascending order, based on a distance value\u001b[39;00m\n\u001b[1;32m     21\u001b[0m neighbors\u001b[38;5;241m=\u001b[39m[]\n",
      "Cell \u001b[0;32mIn[141], line 13\u001b[0m, in \u001b[0;36mKNN.calculate_euclidean\u001b[0;34m(self, sample1, sample2)\u001b[0m\n\u001b[1;32m     11\u001b[0m distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sample1)):\n\u001b[0;32m---> 13\u001b[0m   distance\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m(sample1[i]\u001b[38;5;241m-\u001b[39msample2[i])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m#Euclidean Distance = sqrt(sum i to N (x1_i – x2_i)^2)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sqrt(distance)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf=KNN(10)\n",
    "clf.fit(x_train_hog,y_train)\n",
    "predictions=clf.predict(x_test_hog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7320b8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 3 0 ... 0 1 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " [3 2 2 ... 2 2 0]\n",
      " ...\n",
      " [2 1 1 ... 3 0 0]\n",
      " [1 0 2 ... 1 2 0]\n",
      " [1 0 0 ... 1 1 2]]\n",
      "0.0204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, predictions) #our model\n",
    "print(cm)\n",
    "\n",
    "print (accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6fed8594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0203"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 10, metric = 'minkowski', p = 2)#The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric.\n",
    "classifier.fit(x_train_hog, y_train.ravel())\n",
    "\n",
    "y_pred = classifier.predict(x_test_hog)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2a9d8251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0159\n"
     ]
    }
   ],
   "source": [
    "clf2=KNN(10)\n",
    "clf2.fit(train_features_lbp,y_train)\n",
    "predictions_2=clf2.predict(test_features_lbp)\n",
    "print (accuracy_score(y_test, predictions_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7edc57a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0159"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors = 10, metric = 'minkowski', p = 2)#The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric.\n",
    "classifier.fit(train_features_lbp, y_train.ravel())\n",
    "\n",
    "y_pred = classifier.predict(test_features_lbp)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
