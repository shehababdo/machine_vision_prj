{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0cf22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f79cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 14:59:04.579381: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab546ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Define the number of bins for the histogram\n",
    "num_bins = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15745407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HOG parameters\n",
    "cell_size = (4, 4)           # Size of each cell in pixels\n",
    "block_size = (2, 2)          # Number of cells in a block\n",
    "block_stride = (4, 4)        # Step size for block movement\n",
    "win_size = (32, 32)          # Same as image size\n",
    "nbins = 9                    # Number of orientation bins\n",
    "\n",
    "# Initialize HOG descriptor\n",
    "hog = cv2.HOGDescriptor(\n",
    "    _winSize=(win_size[1], win_size[0]),\n",
    "    _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),\n",
    "    _blockStride=(block_stride[1], block_stride[0]),\n",
    "    _cellSize=(cell_size[1], cell_size[0]),\n",
    "    _nbins=nbins\n",
    ")\n",
    "\n",
    "# Function to compute HOG features for the dataset\n",
    "def compute_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        hog_feats = hog.compute(img).flatten()  # Flatten to 1D vector\n",
    "        features.append(hog_feats)\n",
    "    return np.array(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d0a843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HOG feature shape: (50000, 1764)\n",
      "Test HOG feature shape: (10000, 1764)\n"
     ]
    }
   ],
   "source": [
    "# Convert images to grayscale\n",
    "x_train_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in x_train])\n",
    "x_test_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in x_test])\n",
    "\n",
    "# Extract HOG features for training and test datasets\n",
    "x_train_hog = compute_hog_features(x_train_gray)\n",
    "x_test_hog = compute_hog_features(x_test_gray)\n",
    "\n",
    "print(f\"Training HOG feature shape: {x_train_hog.shape}\")\n",
    "print(f\"Test HOG feature shape: {x_test_hog.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f5d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract color histogram features\n",
    "def color_histogram(image):\n",
    "    # Convert image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Calculate histograms for each color channel\n",
    "    hist_h = cv2.calcHist([hsv_image], [0], None, [num_bins], [0, 180])  # Hue\n",
    "    hist_s = cv2.calcHist([hsv_image], [1], None, [num_bins], [0, 256])  # Saturation\n",
    "    hist_v = cv2.calcHist([hsv_image], [2], None, [num_bins], [0, 256])  # Value\n",
    "\n",
    "    # Normalize histograms\n",
    "    cv2.normalize(hist_h, hist_h, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    cv2.normalize(hist_s, hist_s, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    cv2.normalize(hist_v, hist_v, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "    # Concatenate histograms into a single feature vector\n",
    "    histogram = np.concatenate((hist_h, hist_s, hist_v), axis=0)\n",
    "\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fcfd244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (50000, 768, 1)\n",
      "Test features shape: (10000, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "# Extract features from training and test data\n",
    "train_features_color = []\n",
    "for image in x_train:\n",
    "    feature_c = color_histogram(image)\n",
    "    train_features_color.append(feature_c)\n",
    "\n",
    "test_features_color = []\n",
    "for image in x_test:\n",
    "    feature_c_test = color_histogram(image)\n",
    "    test_features_color.append(feature_c_test)\n",
    "\n",
    "# Convert feature lists to NumPy arrays\n",
    "train_features_color = np.array(train_features_color)\n",
    "test_features_color = np.array(test_features_color)\n",
    "\n",
    "print(\"Training features shape:\", train_features_color.shape)\n",
    "print(\"Test features shape:\", test_features_color.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db362fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute LBP histogram\n",
    "def lbp_histogram(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply LBP operator\n",
    "    lbp = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    lbp = cv2.normalize(lbp, lbp, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Flatten the histogram\n",
    "    hist = lbp.flatten()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bb7b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (50000, 256)\n",
      "Test features shape: (10000, 256)\n"
     ]
    }
   ],
   "source": [
    "# Extract features from training\n",
    "train_features_lbp = []\n",
    "for image in x_train:\n",
    "    feature_lbp = lbp_histogram(image)\n",
    "    train_features_lbp.append(feature_lbp)\n",
    "    \n",
    "# Extract features from test data\n",
    "test_features_lbp = []\n",
    "for image in x_test:\n",
    "    feature_lbp = lbp_histogram(image)\n",
    "    test_features_lbp.append(feature_lbp)\n",
    "    \n",
    "# Convert feature lists to NumPy arrays\n",
    "train_features_lbp = np.array(train_features_lbp)\n",
    "test_features_lbp = np.array(test_features_lbp)\n",
    "\n",
    "print(\"Training features shape:\", train_features_lbp.shape)\n",
    "print(\"Test features shape:\", test_features_lbp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a02d624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans Classifier Implementation\n",
    "class KMeansClassifier:\n",
    "    def __init__(self, n_clusters, max_iter=300, tol=1e-4):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        random_indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
    "        self.centroids = X[random_indices]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)\n",
    "            self.labels = np.argmin(distances, axis=1)\n",
    "\n",
    "            new_centroids = np.array([X[self.labels == k].mean(axis=0) for k in range(self.n_clusters)])\n",
    "            if np.all(np.abs(new_centroids - self.centroids) < self.tol):\n",
    "                break\n",
    "            self.centroids = new_centroids\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)\n",
    "        return np.argmin(distances, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d1474eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KMeans\n",
    "n_clusters = 100  # Number of clusters\n",
    "kmeans = KMeansClassifier(n_clusters=n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d82a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HOG feature shape: (50000, 1)\n",
      "Test HOG feature shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca1 = PCA(n_components=1)\n",
    "pca2 = PCA(n_components=1)\n",
    "# Fit the PCA model to the data\n",
    "pca1.fit(x_train_hog)\n",
    "\n",
    "# Transform the data to the new lower-dimensional space\n",
    "x_train_hog = pca1.transform(x_train_hog)\n",
    "\n",
    "pca2.fit(x_test_hog)\n",
    "\n",
    "# Transform the data to the new lower-dimensional space\n",
    "x_test_hog = pca2.transform(x_test_hog)\n",
    "\n",
    "print(f\"Training HOG feature shape: {x_train_hog.shape}\")\n",
    "print(f\"Test HOG feature shape: {x_test_hog.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17d19935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting KMeans on training data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting KMeans on training data...\")\n",
    "kmeans.fit(x_train_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936c3c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting clusters for test data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting clusters for test data...\")\n",
    "predicted_labels = kmeans.predict(x_test_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6755f80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster assignments for the first 10 test images: [80 88 86 87 77 68 62 48 80 87]\n"
     ]
    }
   ],
   "source": [
    "# Display some results\n",
    "print(\"Cluster assignments for the first 10 test images:\", predicted_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb95a76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print (accuracy_score(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3924ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LBP feature shape: (50000, 1)\n",
      "Test LBP feature shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "pca3 = PCA(n_components=1)\n",
    "pca4 = PCA(n_components=1)\n",
    "# Fit the PCA model to the data\n",
    "pca3.fit(train_features_lbp)\n",
    "\n",
    "# Transform the data to the new lower-dimensional space\n",
    "train_features_lbp = pca3.transform(train_features_lbp)\n",
    "\n",
    "pca4.fit(test_features_lbp)\n",
    "\n",
    "# Transform the data to the new lower-dimensional space\n",
    "test_features_lbp = pca4.transform(test_features_lbp)\n",
    "\n",
    "print(f\"Training LBP feature shape: {train_features_lbp.shape}\")\n",
    "print(f\"Test LBP feature shape: {test_features_lbp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60fb0802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting KMeans on training data...\n",
      "Predicting clusters for test data...\n",
      "0.0104\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting KMeans on training data...\")\n",
    "kmeans.fit(train_features_lbp)\n",
    "\n",
    "print(\"Predicting clusters for test data...\")\n",
    "predicted_labels_lbp = kmeans.predict(test_features_lbp)\n",
    "\n",
    "print (accuracy_score(y_test, predicted_labels_lbp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e9b671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LBP feature shape: (50000, 1)\n",
      "Test LBP feature shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training features\n",
    "train_features_color = train_features_color.reshape(50000, -1)\n",
    "\n",
    "# Reshape the test features\n",
    "test_features_color = test_features_color.reshape(10000, -1)\n",
    "\n",
    "pca5 = PCA(n_components=1)\n",
    "pca6 = PCA(n_components=1)\n",
    "# Fit the PCA model to the data\n",
    "pca5.fit(train_features_color)\n",
    "\n",
    "# Transform the data to the new lower-dimensional space\n",
    "train_features_color = pca5.transform(train_features_color)\n",
    "\n",
    "pca6.fit(test_features_color)\n",
    "\n",
    "# Transform the data to the new lower-dimensional space\n",
    "test_features_color = pca6.transform(test_features_color)\n",
    "\n",
    "print(f\"Training LBP feature shape: {train_features_color.shape}\")\n",
    "print(f\"Test LBP feature shape: {test_features_color.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53682b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting KMeans on training data...\n",
      "Predicting clusters for test data...\n",
      "0.0097\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting KMeans on training data...\")\n",
    "kmeans.fit(train_features_color)\n",
    "\n",
    "print(\"Predicting clusters for test data...\")\n",
    "predicted_labels_color = kmeans.predict(test_features_color)\n",
    "\n",
    "print (accuracy_score(y_test, predicted_labels_color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d441251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
